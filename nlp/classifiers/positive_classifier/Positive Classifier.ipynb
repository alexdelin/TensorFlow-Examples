{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import json\n",
    "\n",
    "\n",
    "def create_training(word_list, article_files, output_file):\n",
    "    \n",
    "    positive_training = []\n",
    "    negative_training = []\n",
    "    \n",
    "    for article in article_files:\n",
    "        with open(article, 'r') as article_file:\n",
    "\n",
    "            article_text = article_file.read()\n",
    "            article_blob = TextBlob(article_text.decode('utf-8'))\n",
    "\n",
    "            for sentence in article_blob.sentences:\n",
    "                \n",
    "                is_positive = False\n",
    "                \n",
    "                try:\n",
    "                    for word in sentence.words:\n",
    "\n",
    "                        if word.string in word_list:\n",
    "                            if sentence.string not in positive_training:\n",
    "\n",
    "                                positive_training.append(sentence.string)\n",
    "                                \n",
    "                            is_positive = True\n",
    "\n",
    "                    if not is_positive:                        \n",
    "                        if sentence.string not in negative_training:\n",
    "                            negative_training.append(sentence.string)\n",
    "                            \n",
    "                except:\n",
    "                    print sentence.string.decode('utf-8')\n",
    "                    \n",
    "    with open(output_file, 'w') as training_file:\n",
    "        \n",
    "        training_output = {\n",
    "            \"positive_training\": positive_training,\n",
    "            \"negative_training\": negative_training\n",
    "        }\n",
    "        \n",
    "        json.dump(training_output, training_file)\n",
    "        \n",
    "    print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import PositiveNaiveBayesClassifier\n",
    "\n",
    "def train_positive_classifier(training_file_name, probability_value):\n",
    "    with open(training_file_name, 'r') as training_file:\n",
    "        training_data = json.load(training_file)\n",
    "\n",
    "        positive_training = training_data['positive_training']\n",
    "        negative_training = training_data['negative_training']\n",
    "\n",
    "    trained_classifier = PositiveNaiveBayesClassifier(positive_training, negative_training, positive_prob_prior=probability_value)\n",
    "    return trained_classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "articles = ['article1.txt', 'article2.txt']\n",
    "\n",
    "increase_words = ['increase', 'increased', 'increases', 'increasing', 'expand', 'expanded', 'expanding', 'jumped', 'grew', 'grown', 'higher', 'growth', 'growing', 'rose', 'boost', 'boosted', 'boosts', 'above', 'winning']\n",
    "decrease_words = ['lower', 'lowered', 'miss', 'decrease', 'shrunk', 'shrank', 'shrinking', 'decreased', 'decreases', 'drop', 'falling', 'below', 'fell', 'fall', 'fallen', 'losing', 'dissapointing', 'dropped', 'droppping', 'plunge', 'plunges', 'plunging']\n",
    "consistent_words = ['consistent', 'in line with', 'equal', 'about', 'similar', 'around', 'near']\n",
    "\n",
    "increase_training_filename = 'increase_training.json'\n",
    "decrease_training_filename = 'decrease_training.json'\n",
    "consistent_training_filename = 'consistent_training.json'\n",
    "\n",
    "create_training(increase_words, articles, increase_training_filename)\n",
    "create_training(decrease_words, articles, decrease_training_filename)\n",
    "create_training(consistent_words, articles, consistent_training_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_increase_classifier = train_positive_classifier(increase_training_filename, 0.01)\n",
    "test_decrease_classifier = train_positive_classifier(decrease_training_filename, 0.01)\n",
    "test_consistent_classifier = train_positive_classifier(consistent_training_filename, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PositiveNaiveBayesClassifier trained on 105 labeled and 588 unlabeled instances>\n",
      "<PositiveNaiveBayesClassifier trained on 70 labeled and 623 unlabeled instances>\n",
      "<PositiveNaiveBayesClassifier trained on 41 labeled and 652 unlabeled instances>\n"
     ]
    }
   ],
   "source": [
    "print repr(test_increase_classifier)\n",
    "print repr(test_decrease_classifier)\n",
    "print repr(test_consistent_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increase Classifier: False\n",
      "Decrease Classifier: True\n",
      "Consistent Classifier: False\n"
     ]
    }
   ],
   "source": [
    "test_string = 'revenue and earnings were unchanged'\n",
    "print 'Increase Classifier: {}'.format(test_increase_classifier.classify(test_string))\n",
    "print 'Decrease Classifier: {}'.format(test_decrease_classifier.classify(test_string))\n",
    "print 'Consistent Classifier: {}'.format(test_consistent_classifier.classify(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_classifier(training_file, eval_file):\n",
    "    '''\n",
    "    input data format:\n",
    "        training_file='training_data.json',\n",
    "        test_set=[{\n",
    "            'text': 'sample test text',\n",
    "            'value': True\n",
    "        }]\n",
    "    '''\n",
    "    \n",
    "    with open(eval_file, 'r') as eval_data:\n",
    "        test_set = json.load(eval_data)\n",
    "        \n",
    "        \n",
    "    a = range(30)\n",
    "    weight_list = [round(number * .01, 2) for number in a]\n",
    "    \n",
    "    for weight_value in weight_list:\n",
    "\n",
    "        test_classifier = train_positive_classifier(training_file, weight_value)\n",
    "        error_count = 0\n",
    "        correct_count = 0\n",
    "        error_ids = []\n",
    "        \n",
    "        for test_item in test_set:\n",
    "            \n",
    "            # Handling for failures\n",
    "            if test_classifier.classify(test_item['text']) != test_item['value']:\n",
    "                error_count += 1\n",
    "                if test_item.get('id'):\n",
    "                    error_ids.append(test_item['id'])\n",
    "            else:\n",
    "                correct_count += 1\n",
    "\n",
    "        print 'For Weight:{}  - Got {} Failures and {} Correct'.format(weight_value, error_count, correct_count)\n",
    "        if len(error_ids) > 0:\n",
    "            print 'Failed on test ids {}'.format(', '.join(error_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Weight:0.0  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 1, 3, 5, 6, 10\n",
      "For Weight:0.01  - Got 4 Failures and 7 Correct\n",
      "Failed on test ids 6, 7, 9, 10\n",
      "For Weight:0.02  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 6, 7, 9\n",
      "For Weight:0.03  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 6, 7, 9\n",
      "For Weight:0.04  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 6, 7, 9\n",
      "For Weight:0.05  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 6, 7, 9\n",
      "For Weight:0.06  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 6, 7, 9\n",
      "For Weight:0.07  - Got 2 Failures and 9 Correct\n",
      "Failed on test ids 7, 9\n",
      "For Weight:0.08  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.09  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.1  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.11  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.12  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.13  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.14  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.15  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.16  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.17  - Got 3 Failures and 8 Correct\n",
      "Failed on test ids 7, 8, 9\n",
      "For Weight:0.18  - Got 4 Failures and 7 Correct\n",
      "Failed on test ids 4, 7, 8, 9\n",
      "For Weight:0.19  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.2  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.21  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.22  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.23  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.24  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.25  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.26  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.27  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.28  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n",
      "For Weight:0.29  - Got 5 Failures and 6 Correct\n",
      "Failed on test ids 4, 7, 8, 9, 11\n"
     ]
    }
   ],
   "source": [
    "optimize_classifier('increase_training.json', 'increase_eval.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
